# ğŸ§  VisionFlow: Modular CV Inference API

![Python 3.10+](https://img.shields.io/badge/python-3.10%2B-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100.0-009688.svg)
![Docker Support](https://img.shields.io/badge/Docker-Ready-2496ED.svg)

An industrial-grade computer vision microservice designed for model inference. Built with **FastAPI**, optimized for **Docker environments**, and structured to scale across multiple vision tasks like classification and object detection.

---

## ğŸ—‚ Overview

This system is optimized for:

- Serving multiple CV models via HTTP APIs
- Handling large-scale requests with configurable **rate limiting**
- Plug-and-play extensibility for new tasks, models, or strategies

Ideal for deploying computer vision inference systems in production environments.

---

## ğŸ“Œ Index

- [Key Capabilities](#key-capabilities)
- [System Design](#system-design)
- [How to Launch](#how-to-launch)
- [File Guide](#file-guide)
- [Environment Settings](#environment-settings)
- [API Interface](#api-interface)
- [Throttle Controls](#throttle-controls)
- [Plug-in Extensions](#plug-in-extensions)
- [Validation & Testing](#validation--testing)
- [Production Deployment (Docker)](#production-deployment-docker)
- [Development & Contribution](#development--contribution)
- [License](#license)

---

## âœ… Key Capabilities

- ğŸ§  **Multi-task Inference**: Use models like YOLO or EfficientNet for classification, detection, and custom use-cases.
- ğŸ§© **Modular Expansion**: Swap models, modify pipelines, or insert new preprocess/postprocess steps.
- ğŸ•µï¸ **Custom Strategies**: Tailor prediction logic using modular "strategy" classes.
- ğŸš¥ **Rate Management**: Redis-based request limiting prevents abuse and stabilizes access.
- ğŸ“¦ **Container-First**: Docker images for simplified setup and deployment.
- ğŸ§ª **Full Test Coverage**: Includes unit tests, integration tests, and API contract checks.

---

## ğŸ§± System Design

```
project-root/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ conf/                 â† YAML/ENV configurations
â”‚   â”œâ”€â”€ schema/               â† API data models
â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”œâ”€â”€ constants/        â† Image-related constants
â”‚   â”‚   â”œâ”€â”€ models/           â† Model wrappers (YOLO, EfficientNet)
â”‚   â”‚   â”œâ”€â”€ pipelines/        â† Execution logic (pre â†’ model â†’ post)
â”‚   â”‚   â”œâ”€â”€ processing/       â† Preprocessing and postprocessing modules
â”‚   â”‚   â”œâ”€â”€ prediction_strategies/
â”‚   â”‚   â”œâ”€â”€ tools.py
â”‚   â”‚   â””â”€â”€ service.py        â† FastAPI app entry point
â”‚   â”œâ”€â”€ settings/
â”‚   â””â”€â”€ logger.py
```

---

## âš¡ How to Launch

### Option 1: Use Docker (Production-Ready)

```bash
git clone https://github.com/your-org/vision-inference-pipeline.git
cd vision-inference-pipeline
cp .env.example .env   # update settings
docker-compose up --build
```

ğŸ“ App will be live at `http://localhost:8000`  
ğŸ“š Swagger UI: `http://localhost:8000/docs`

---

### Option 2: Local Dev Setup (with Poetry)

```bash
git clone https://github.com/your-org/vision-inference-pipeline.git
cd vision-inference-pipeline
poetry install
cp .env.example .env
poetry shell
python src/run_service.py
```

---

## ğŸ“‚ File Guide

| Folder | Purpose |
|--------|---------|
| `conf/` | Config settings for the models and pipelines |
| `models/` | Detection & classification models (YOLO, EfficientNet) |
| `processing/` | Input/output transformation layers |
| `pipelines/` | Flow logic for each CV task |
| `prediction_strategies/` | Rotation-based or fallback logic |
| `settings/` | App-level constants and .env loader |

---

## âš™ï¸ Environment Settings

All runtime behavior (model path, allowed hosts, Redis setup, etc.) is configured via the `.env` file and loaded by the service settings module.

---

## ğŸ”Œ API Interface

Interactive API documentation is available at:

```
http://localhost:8000/docs
```

Typical endpoints:
- `POST /predict/classify`
- `POST /predict/detect`
- `GET /health`

---

## ğŸ›¡ï¸ Throttle Controls

Enable and configure Redis-based rate limiting to protect API routes. Useful in high-traffic or public deployments.

---

## ğŸ§° Plug-in Extensions

You can easily expand the system by:

- ğŸ“Œ Adding new models (drop them under `models/`)
- âœ‚ï¸ Creating new preprocessors
- ğŸ§  Building post-processing logic
- ğŸ” Crafting new prediction strategies

All extensions can be auto-registered using decorators or the factory pattern.

---

## ğŸ§ª Validation & Testing

Run tests using:

```bash
pytest
```

Covers unit tests, route checks, and pipeline validation.

---

## ğŸ“¦ Production Deployment (Docker)

Use the provided Dockerfile and `docker-compose.yml` for reproducible, containerized deployment. Compatible with major container orchestration tools.

---

